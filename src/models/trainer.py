"""
–û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    1. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –º–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∞–º (skewness)
    2. –û–±—É—á–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞:
        - Main Model: —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã (std-–ø—Ä–∏–∑–Ω–∞–∫–∏)
        - Meta Model: —Ñ–∏–ª—å—Ç—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞ (skewness-–ø—Ä–∏–∑–Ω–∞–∫–∏)
    3. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—Ç–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from catboost import CatBoostClassifier

from src.data.loader import load_price_data
from src.features.engineering import create_features, get_feature_columns
from src.labeling.strategies import get_labels_one_direction
from src.models.validator import (
    validate_class_balance,
    validate_sample_size,
    validate_cluster_sizes
)
from src.backtesting.tester import test_model_one_direction


class ClusterModelTrainer:
    """
    –¢—Ä–µ–Ω–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
    
    Workflow:
        1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        2. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (std + skewness)
        3. –†–∞–∑–º–µ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        4. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ meta-–ø—Ä–∏–∑–Ω–∞–∫–∞–º
        5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
        6. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—Ç–±–æ—Ä –ª—É—á—à–µ–π
    
    Attributes:
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
        data: –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        clusters: –ú–µ—Ç–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        models: –û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
    """
    
    def __init__(self, config: dict):
        """
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è
        """
        self.config = config
        self.data = None
        self.clusters = None
        self.models = {}
        
        print(f"\n{'='*70}")
        print(f"  üéØ CLUSTER MODEL TRAINER")
        print(f"{'='*70}")
        print(f"  Symbol: {config['symbol']['name']}")
        print(f"  Direction: {config['trading']['direction'].upper()}")
        print(f"  N Clusters: {config.get('n_clusters', config['clustering']['n_clusters'])}")
        print(f"{'='*70}\n")
    
    def train_all_clusters(self) -> List[Dict]:
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        
        Returns:
            list: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
            [
                {
                    'cluster': 0,
                    'model': CatBoostClassifier,
                    'meta_model': CatBoostClassifier,
                    'val_acc': 0.78,
                    'r2': 0.92,
                    'samples': 1200,
                    'balance': 0.45,
                    'dataset': DataFrame  # –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                },
                ...
            ]
        """
        # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        print("üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        self._prepare_data()
        
        # 2. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
        print(f"\nüî¨ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è...")
        self._perform_clustering()
        
        # 3. –û–±—É—á–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
        results = []
        n_clusters = len(np.unique(self.clusters))
        
        print(f"\nüéì –û–±—É—á–µ–Ω–∏–µ {n_clusters} –º–æ–¥–µ–ª–µ–π...")
        
        for cluster_id in range(n_clusters):
            print(f"\n  –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}:")
            
            try:
                result = self._train_single_cluster(cluster_id)
                
                if result is not None:
                    results.append(result)
                    print(f"    ‚úì Val Acc: {result['val_acc']:.4f} | "
                          f"R¬≤: {result['r2']:.4f} | "
                          f"Samples: {result['samples']}")
                else:
                    print(f"    ‚úó –ü—Ä–æ–ø—É—â–µ–Ω")
                    
            except Exception as e:
                print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
                continue
        
        print(f"\n{'‚îÄ'*70}")
        print(f"  ‚úÖ –û–±—É—á–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(results)}/{n_clusters}")
        print(f"{'‚îÄ'*70}\n")
        
        return results
    
    def _prepare_data(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞, —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ä–∞–∑–º–µ—Ç–∫–∞"""
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ü–µ–Ω
        prices = load_price_data(self.config)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        periods = self.config['periods']
        meta_periods = self.config['periods_meta']
        
        features = create_features(prices, periods, meta_periods)
        
        # –†–∞–∑–º–µ—Ç–∫–∞
        labeled = get_labels_one_direction(
            features,
            markup=self.config['markup'],
            min_bars=self.config['trading']['labeling']['min_bars'],
            max_bars=self.config['trading']['labeling']['max_bars'],
            direction=self.config['trading']['direction']
        )
        
        self.data = labeled
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        valid, errors = self._validate_data()
        if not valid:
            raise ValueError(f"–î–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é: {errors}")
    
    def _validate_data(self) -> Tuple[bool, List[str]]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        errors = []
        
        # –†–∞–∑–º–µ—Ä
        min_samples = self.config.get('min_samples', 1000)
        valid, msg = validate_sample_size(self.data, min_samples)
        if not valid:
            errors.append(msg)
        
        # –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
        min_balance = self.config['validation']['criteria']['min_class_balance']
        valid, balance, msg = validate_class_balance(
            self.data['labels'],
            min_balance
        )
        if not valid:
            errors.append(msg)
        
        return len(errors) == 0, errors
    
    def _perform_clustering(self) -> None:
        """
        –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –º–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∞–º
        
        –ê–ª–≥–æ—Ä–∏—Ç–º:
            1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ meta-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (skewness)
            2. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ StandardScaler
            3. KMeans –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
            4. –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        """
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ meta-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        meta_cols = get_feature_columns(self.data, 'meta_')
        
        if len(meta_cols) == 0:
            raise ValueError("–ù–µ—Ç –º–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
        
        meta_features = self.data[meta_cols].values
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        scaler = StandardScaler()
        meta_scaled = scaler.fit_transform(meta_features)
        
        # KMeans
        n_clusters = self.config.get('n_clusters', 
                                    self.config['clustering']['n_clusters'])
        random_state = self.config['clustering']['random_state']
        n_init = self.config['clustering']['n_init']
        
        kmeans = KMeans(
            n_clusters=n_clusters,
            random_state=random_state,
            n_init=n_init
        )
        
        self.clusters = kmeans.fit_predict(meta_scaled)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        min_cluster_size = self.config.get('min_samples', 100)
        valid, sizes, msg = validate_cluster_sizes(
            self.clusters,
            min_cluster_size
        )
        
        print(f"  –ö–ª–∞—Å—Ç–µ—Ä–æ–≤: {n_clusters}")
        print(f"  –†–∞–∑–º–µ—Ä—ã: {sizes}")
        
        if not valid:
            print(f"  ‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: {msg}")
    
    def _train_single_cluster(self, cluster_id: int) -> Optional[Dict]:
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
        
        Args:
            cluster_id: ID –∫–ª–∞—Å—Ç–µ—Ä–∞
        
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        # –û—Ç–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–∞
        cluster_mask = self.clusters == cluster_id
        cluster_data = self.data[cluster_mask].copy()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
        min_samples = self.config.get('min_samples', 100)
        if len(cluster_data) < min_samples:
            print(f"    –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö: {len(cluster_data)} < {min_samples}")
            return None
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞
        min_balance = self.config['validation']['criteria']['min_class_balance']
        valid, balance, msg = validate_class_balance(
            cluster_data['labels'],
            min_balance
        )
        
        if not valid:
            print(f"    –î–∏—Å–±–∞–ª–∞–Ω—Å: {balance:.3f} < {min_balance}")
            return None
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        train_data, test_data = self._split_data(cluster_data)
        
        # –û–±—É—á–µ–Ω–∏–µ Main Model (—Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã)
        main_model = self._train_main_model(train_data, test_data)
        
        # –û–±—É—á–µ–Ω–∏–µ Meta Model (—Ñ–∏–ª—å—Ç—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞)
        meta_model = self._train_meta_model(train_data, test_data)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        val_acc = main_model.score(
            test_data[get_feature_columns(test_data, 'feat_')],
            test_data['labels']
        )
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è R¬≤ —Ç–µ—Å—Ç–∞
        test_dataset = self._prepare_test_dataset(
            cluster_data,
            main_model,
            meta_model
        )
        
        # –†–∞—Å—á–µ—Ç R¬≤ (–∫–∞—á–µ—Å—Ç–≤–æ —Ç–æ—Ä–≥–æ–≤–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏)
        r2 = test_model_one_direction(
            dataset=test_dataset,
            result=[main_model, meta_model],
            config=self.config,
            plt=False
        )
        
        return {
            'cluster': cluster_id,
            'model': main_model,
            'meta_model': meta_model,
            'val_acc': val_acc,
            'r2': r2,
            'samples': len(cluster_data),
            'balance': balance,
            'dataset': test_dataset
        }
    
    def _split_data(self, data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞"""
        train_size = self.config['validation']['train_size']
        shuffle = self.config['validation']['shuffle']
        stratify = self.config['validation']['stratify']
        random_state = self.config['validation']['random_state']
        
        if shuffle and stratify:
            # –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
            train_data, test_data = train_test_split(
                data,
                train_size=train_size,
                shuffle=True,
                stratify=data['labels'],
                random_state=random_state
            )
        else:
            # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
            split_idx = int(len(data) * train_size)
            train_data = data.iloc[:split_idx]
            test_data = data.iloc[split_idx:]
        
        return train_data, test_data
    
    def _train_main_model(self,
                         train_data: pd.DataFrame,
                         test_data: pd.DataFrame) -> CatBoostClassifier:
        """
        –û–±—É—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ (—Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã)
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç std-–ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        """
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏ –º–µ—Ç–∫–∏
        feat_cols = get_feature_columns(train_data, 'feat_')
        X_train = train_data[feat_cols]
        y_train = train_data['labels'].astype('int16')
        X_test = test_data[feat_cols]
        y_test = test_data['labels'].astype('int16')
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        model_params = self.config['model']['main']['params'].copy()
        
        # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –ø–æ–∏—Å–∫–∞
        if 'iterations' in self.config:
            model_params['iterations'] = self.config['iterations']
        if 'depth' in self.config:
            model_params['depth'] = self.config['depth']
        
        # –û–±—É—á–µ–Ω–∏–µ
        model = CatBoostClassifier(**model_params)
        model.fit(
            X_train, y_train,
            eval_set=(X_test, y_test),
            early_stopping_rounds=model_params.get('early_stopping_rounds', 50),
            plot=False
        )
        
        return model
    
    def _train_meta_model(self,
                         train_data: pd.DataFrame,
                         test_data: pd.DataFrame) -> CatBoostClassifier:
        """
        –û–±—É—á–µ–Ω–∏–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ (—Ñ–∏–ª—å—Ç—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞)
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç skewness-–ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ–∂–∏–º–∞ —Ä—ã–Ω–∫–∞
        """
        # –ú–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏
        meta_cols = get_feature_columns(train_data, 'meta_')
        
        # –ï—Å–ª–∏ –º–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if len(meta_cols) == 0:
            meta_cols = get_feature_columns(train_data, 'feat_')
        
        X_train = train_data[meta_cols]
        y_train = train_data['labels'].astype('int16')
        X_test = test_data[meta_cols]
        y_test = test_data['labels'].astype('int16')
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ (–æ–±—ã—á–Ω–æ –ø—Ä–æ—â–µ —á–µ–º main)
        meta_params = self.config['model']['meta']['params'].copy()
        
        # –û–±—É—á–µ–Ω–∏–µ
        meta_model = CatBoostClassifier(**meta_params)
        meta_model.fit(
            X_train, y_train,
            eval_set=(X_test, y_test),
            early_stopping_rounds=meta_params.get('early_stopping_rounds', 30),
            plot=False
        )
        
        return meta_model
    
    def _prepare_test_dataset(self,
                             data: pd.DataFrame,
                             main_model: CatBoostClassifier,
                             meta_model: CatBoostClassifier) -> pd.DataFrame:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è R¬≤ —Ç–µ—Å—Ç–∞
        
        –î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∫–∞–∫ labels –∏ meta_labels
        """
        dataset = data.copy()
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏
        feat_cols = get_feature_columns(dataset, 'feat_')
        meta_cols = get_feature_columns(dataset, 'meta_')
        
        if len(meta_cols) == 0:
            meta_cols = feat_cols
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        dataset['labels'] = main_model.predict_proba(dataset[feat_cols])[:, 1]
        dataset['meta_labels'] = meta_model.predict_proba(dataset[meta_cols])[:, 1]
        
        # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è (–ø–æ—Ä–æ–≥ 0.5)
        dataset['labels'] = dataset['labels'].apply(lambda x: 1.0 if x >= 0.5 else 0.0)
        dataset['meta_labels'] = dataset['meta_labels'].apply(lambda x: 1.0 if x >= 0.5 else 0.0)
        
        return dataset


# === –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –£–¢–ò–õ–ò–¢–´ ===

def select_best_model(results: List[Dict],
                     metric: str = 'val_acc') -> Dict:
    """
    –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Args:
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è
        metric: –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è ('val_acc', 'r2')
    
    Returns:
        dict: –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å
    """
    if not results:
        raise ValueError("–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞")
    
    return max(results, key=lambda x: x[metric])


def save_model(result: Dict, filepath: str) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∏—Å–∫
    
    Args:
        result: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—É—á–µ–Ω–∏—è —Å –º–æ–¥–µ–ª—è–º–∏
        filepath: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (.cbm)
    """
    result['model'].save_model(filepath)
    print(f"‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filepath}")


def load_model(filepath: str) -> CatBoostClassifier:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å –¥–∏—Å–∫–∞
    
    Args:
        filepath: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É .cbm
    
    Returns:
        CatBoostClassifier: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    """
    model = CatBoostClassifier()
    model.load_model(filepath)
    print(f"‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {filepath}")
    return model