import numpy as np
import pandas as pd
from typing import Dict, List, Optional
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from catboost import CatBoostClassifier, CatBoostRegressor, Pool

from src.data.loader import load_price_data
from src.features.engineering import create_features, get_feature_columns
from src.labeling.continuous import get_continuous_labels
from src.features.multiframe import add_multiframe_to_existing

class ClusterModelTrainer:
    def __init__(self, config: dict):
        self.config = config
        self.data = None
        self.clusters = None
        
    def train_all_clusters(self) -> List[Dict]:
        self._prepare_data()
        
        n_clusters = self.config['clustering'].get('n_clusters', 1)
        
        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ, –æ—Ç–∫–ª—é—á–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é
        if len(self.data) < 500:
            print("‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞.")
            n_clusters = 1

        if n_clusters > 1:
            self._perform_clustering()
        else:
            self.clusters = np.zeros(len(self.data), dtype=int)
        
        results = []
        for cluster_id in range(n_clusters):
            print(f"\n‚ö° –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∞ {cluster_id}...")
            res = self._train_single_cluster(cluster_id)
            if res:
                results.append(res)
        return results
    
    def _prepare_data(self) -> None:
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        prices = load_price_data(self.config)
        
        # 1. –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features = create_features(
            prices, 
            self.config['periods'], 
            self.config['periods_meta']
        )
        
        # 2. –ú—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if self.config['data']['multiframe']['enabled']:
            print("üåê –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
            try:
                features = add_multiframe_to_existing(
                    primary_data=features,
                    data_path=self.config['data']['paths']['raw'],
                    symbol=self.config['symbol']['name'].split('_')[0],
                    primary_tf=self.config['symbol']['timeframe'],
                    context_tfs=self.config['data']['multiframe']['timeframes']
                )
                print(f"   –ò—Ç–æ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {len(features.columns)}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–∞: {e}")
                print("   –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ç–æ–ª—å–∫–æ —Å –±–∞–∑–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏.")
        
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ OHLC –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ç–∞—Ä–≥–µ—Ç–∞
        aligned_prices = prices.loc[features.index]
        features['high'] = aligned_prices['high']
        features['low'] = aligned_prices['low']
        features['open'] = aligned_prices['open'] # –ù—É–∂–Ω–æ –¥–ª—è ATR –∏–Ω–æ–≥–¥–∞
        
        # 3. –†–∞–∑–º–µ—Ç–∫–∞
        print("üè∑Ô∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π...")
        self.data = get_continuous_labels(
            features,
            max_bars=self.config['trading']['labeling']['max_bars'],
            direction=self.config['trading']['direction'],
            decay_factor=self.config['trading']['labeling'].get('decay', 0.96)
        )
            
    def _perform_clustering(self) -> None:
        meta_cols = get_feature_columns(self.data, 'meta_')
        if not meta_cols:
            meta_cols = get_feature_columns(self.data, 'feat_')[:5]
            
        X = self.data[meta_cols].values
        # –ó–∞—â–∏—Ç–∞ –æ—Ç NaN –ø—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        if np.isnan(X).any():
            X = np.nan_to_num(X)
            
        X = StandardScaler().fit_transform(X)
        
        kmeans = KMeans(
            n_clusters=self.config['clustering']['n_clusters'],
            random_state=42,
            n_init=10
        )
        self.clusters = kmeans.fit_predict(X)
        
    def _train_single_cluster(self, cluster_id: int) -> Optional[Dict]:
        mask = self.clusters == cluster_id
        cluster_data = self.data[mask].copy()
        
        if len(cluster_data) < 100:
            print(f"   –ü—Ä–æ–ø—É—Å–∫ –∫–ª–∞—Å—Ç–µ—Ä–∞ {cluster_id}: –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö ({len(cluster_data)})")
            return None
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ Train/Test (–±–µ–∑ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)
        split_idx = int(len(cluster_data) * 0.8)
        train_df = cluster_data.iloc[:split_idx]
        test_df = cluster_data.iloc[split_idx:]
        
        # –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∏—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ)
        all_cols = cluster_data.columns
        exclude_cols = ['labels', 'target', 'open', 'high', 'low', 'close', 'volume', 'atr']
        feat_cols = [c for c in all_cols if c not in exclude_cols]
        
        # === 1. MAIN MODEL (Regression) ===
        params = self.config['model']['main']['params'].copy()
        if 'custom_loss' in params: del params['custom_loss']
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–π —Ç–∞—Ä–≥–µ—Ç –≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
        if train_df['labels'].nunique() <= 1:
            print("   ‚ö†Ô∏è –û—à–∏–±–∫–∞: Target —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ. –ü—Ä–æ–ø—É—Å–∫.")
            return None

        model = CatBoostRegressor(**params)
        model.fit(
            train_df[feat_cols], train_df['labels'],
            eval_set=(test_df[feat_cols], test_df['labels']),
            early_stopping_rounds=50,
            verbose=False
        )
        
        r2 = model.score(test_df[feat_cols], test_df['labels'])
        print(f"   Cluster {cluster_id} Main R2: {r2:.4f}")
        
        # === 2. META MODEL (Classifier) ===
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –û–±—É—á–∞–µ–º –º–µ—Ç–∞-–º–æ–¥–µ–ª—å —Ä–∞–∑–ª–∏—á–∞—Ç—å —Ö–æ—Ä–æ—à–∏–µ –∏ –ø–ª–æ—Ö–∏–µ –≤—Ö–æ–¥—ã
        # –ï—Å–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–µ—Ç, –º–µ—Ç–∞-–º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –Ω–∞ –æ—à–∏–±–∫–∞—Ö –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏
        
        meta_params = self.config['model']['meta']['params'].copy()
        meta_model = CatBoostClassifier(**meta_params)
        
        # –°–æ–∑–¥–∞–µ–º –±–∏–Ω–∞—Ä–Ω—ã–π —Ç–∞—Ä–≥–µ—Ç –¥–ª—è –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏:
        # 1 = –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ > 0.5 –ò —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å > 0.5 (True Positive)
        # 0 = –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω–æ–µ
        # –ù–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Å–µ–π—á–∞—Å: 1 = —Ä–µ–∞–ª—å–Ω–∞—è –ø—Ä–∏–±—ã–ª—å > 0.5, 0 = –∏–Ω–∞—á–µ
        meta_target = (train_df['labels'] > 0.5).astype(int)
        
        # –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –µ—Å—Ç—å –æ–±–∞ –∫–ª–∞—Å—Å–∞ (0 –∏ 1)
        if meta_target.nunique() > 1:
            meta_model.fit(train_df[feat_cols], meta_target, verbose=False)
        else:
            # –ï—Å–ª–∏ –∫–ª–∞—Å—Å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤—Å–µ —Å–¥–µ–ª–∫–∏ –ø—Ä–∏–±—ã–ª—å–Ω—ã–µ –∏–ª–∏ –≤—Å–µ —É–±—ã—Ç–æ—á–Ω—ã–µ),
            # —Å–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å ONNX
            print("   ‚ö†Ô∏è Meta target const. Creating dummy meta model.")
            dummy_X = train_df[feat_cols].iloc[:2]
            dummy_y = [0, 1] # –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã
            meta_model.fit(dummy_X, dummy_y, verbose=False)
        
        return {
            'cluster': cluster_id,
            'model': model,
            'meta_model': meta_model,
            'val_acc': r2, # –ò—Å–ø–æ–ª—å–∑—É–µ–º R2 –∫–∞–∫ –º–µ—Ç—Ä–∏–∫—É
            'r2': r2,
            'dataset': test_df
        }

def select_best_model(results: List[Dict], metric: str = 'val_acc') -> Dict:
    if not results:
        raise ValueError("–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è")
    return max(results, key=lambda x: x.get(metric, -float('inf')))

def save_model(result: Dict, filepath: str) -> None:
    if 'model' in result:
        result['model'].save_model(filepath)

def load_model(filepath: str) -> CatBoostRegressor:
    model = CatBoostRegressor()
    model.load_model(filepath)
    return model