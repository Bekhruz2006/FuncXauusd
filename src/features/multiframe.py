"""
–ú—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã

–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ 2:
    - –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ (1m - 1Month)
    - –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤—ã—Å—à–∏—Ö –¢–§ –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    - –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
    - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –æ—Å–Ω–æ–≤–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

–ò–¥–µ—è:
    –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, H1),
    –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å –≤—ã—Å—à–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤:
    - –î–Ω–µ–≤–Ω–æ–π —Ç—Ä–µ–Ω–¥ (D1)
    - –ù–µ–¥–µ–ª—å–Ω—ã–µ High/Low (W1)
    - –ú–µ—Å—è—á–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (MN)
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from datetime import datetime


# –ú–∞–ø–ø–∏–Ω–≥ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –Ω–∞ pandas freq
TIMEFRAME_MAP = {
    '1m': '1T',
    '5m': '5T',
    '15m': '15T',
    '30m': '30T',
    'H1': '1H',
    '1h': '1H',
    'H4': '4H',
    '4h': '4H',
    'D1': '1D',
    '1d': '1D',
    'W1': '1W',
    '1w': '1W',
    'MN': '1M',
    '1Month': '1M'
}

# –ò–µ—Ä–∞—Ä—Ö–∏—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ (–æ—Ç –º–µ–Ω—å—à–µ–≥–æ –∫ –±–æ–ª—å—à–µ–º—É)
TIMEFRAME_HIERARCHY = [
    '1m', '5m', '15m', '30m', 'H1', 'H4', 'D1', 'W1', 'MN'
]


class MultiframeLoader:
    """
    –ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
    
    Attributes:
        data_path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å CSV —Ñ–∞–π–ª–∞–º–∏
        symbol: –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'XAUUSD')
        primary_tf: –û—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        context_tfs: –°–ø–∏—Å–æ–∫ –≤—ã—Å—à–∏—Ö –¢–§ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    """
    
    def __init__(self,
                 data_path: str,
                 symbol: str,
                 primary_tf: str = 'H1',
                 context_tfs: Optional[List[str]] = None):
        """
        Args:
            data_path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –¥–∞–Ω–Ω—ã–º–∏
            symbol: –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç (XAUUSD, EURUSD –∏ —Ç.–¥.)
            primary_tf: –û—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º
            context_tfs: –í—ã—Å—à–∏–µ –¢–§ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é D1, W1, MN)
        """
        self.data_path = Path(data_path)
        self.symbol = symbol
        self.primary_tf = primary_tf
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¢–§ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if context_tfs is None:
            self.context_tfs = self._get_higher_timeframes(primary_tf)
        else:
            self.context_tfs = context_tfs
        
        print(f"üìä MultiframeLoader –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:")
        print(f"  ‚Ä¢ Symbol: {symbol}")
        print(f"  ‚Ä¢ Primary TF: {primary_tf}")
        print(f"  ‚Ä¢ Context TFs: {', '.join(self.context_tfs)}")
    
    def _get_higher_timeframes(self, base_tf: str) -> List[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—ã—Å—à–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–∞–∑–æ–≤–æ–≥–æ
        
        Args:
            base_tf: –ë–∞–∑–æ–≤—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º
        
        Returns:
            list: –°–ø–∏—Å–æ–∫ –≤—ã—Å—à–∏—Ö –¢–§
        """
        try:
            base_idx = TIMEFRAME_HIERARCHY.index(base_tf)
        except ValueError:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º D1, W1, MN
            return ['D1', 'W1', 'MN']
        
        # –ë–µ—Ä–µ–º –≤—Å–µ –≤—ã—à–µ –±–∞–∑–æ–≤–æ–≥–æ
        higher = TIMEFRAME_HIERARCHY[base_idx + 1:]
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º (2-3 –¢–§)
        return higher[:3] if higher else []
    
    def load_timeframe(self, timeframe: str) -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
        
        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        
        Returns:
            pd.DataFrame: –î–∞–Ω–Ω—ã–µ —Å –∏–Ω–¥–µ–∫—Å–æ–º datetime
        
        Raises:
            FileNotFoundError: –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞ (—Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è)
        possible_names = [
            f"{self.symbol}_{timeframe}.csv",
            f"{self.symbol.lower()}_{timeframe}.csv",
            f"{self.symbol}_{timeframe.lower()}.csv",
            f"{self.symbol.upper()}_{timeframe.upper()}.csv",
        ]
        
        filepath = None
        for name in possible_names:
            candidate = self.data_path / name
            if candidate.exists():
                filepath = candidate
                break
        
        if filepath is None:
            raise FileNotFoundError(
                f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª –¥–ª—è {timeframe}. "
                f"–ò—Å–∫–∞–ª: {possible_names}"
            )
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä)
        df = self._parse_csv(filepath)
        
        print(f"  ‚úì {timeframe}: {len(df)} –±–∞—Ä–æ–≤ "
              f"({df.index[0]} - {df.index[-1]})")
        
        return df
    
    def _parse_csv(self, filepath: Path) -> pd.DataFrame:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä MT5 CSV
        
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
            - –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å ';'
            - –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –ø—Ä–æ–±–µ–ª
            - –§–æ—Ä–º–∞—Ç Date;Open;High;Low;Close;Volume
        """
        # –ü–æ–ø—ã—Ç–∫–∞ 1: —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å ';'
        try:
            df = pd.read_csv(filepath, sep=';', parse_dates=['Date'])
            if 'Date' in df.columns and 'Close' in df.columns:
                result = pd.DataFrame()
                result['time'] = pd.to_datetime(df['Date'])
                result['open'] = df['Open'].astype(float)
                result['high'] = df['High'].astype(float)
                result['low'] = df['Low'].astype(float)
                result['close'] = df['Close'].astype(float)
                result['volume'] = df['Volume'].astype(float)
                result.set_index('time', inplace=True)
                return result.dropna()
        except:
            pass
        
        # –ü–æ–ø—ã—Ç–∫–∞ 2: —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –ø—Ä–æ–±–µ–ª
        try:
            df = pd.read_csv(filepath, sep=r'\s+')
            if '<DATE>' in df.columns:
                result = pd.DataFrame()
                result['time'] = df['<DATE>'] + ' ' + df['<TIME>']
                result['time'] = pd.to_datetime(result['time'], format='mixed')
                result['open'] = df['<OPEN>'].astype(float)
                result['high'] = df['<HIGH>'].astype(float)
                result['low'] = df['<LOW>'].astype(float)
                result['close'] = df['<CLOSE>'].astype(float)
                result['volume'] = df['<TICKVOL>'].astype(float)
                result.set_index('time', inplace=True)
                return result.dropna()
        except:
            pass
        
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å {filepath.name}")
    
    def load_all(self) -> Dict[str, pd.DataFrame]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        
        Returns:
            dict: {timeframe: DataFrame}
        """
        data = {}
        
        print(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤:")
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –¢–§
        data[self.primary_tf] = self.load_timeframe(self.primary_tf)
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¢–§
        for tf in self.context_tfs:
            try:
                data[tf] = self.load_timeframe(tf)
            except FileNotFoundError as e:
                print(f"  ‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω {tf}: {e}")
                continue
        
        return data
    
    def resample_to_primary(self,
                           higher_tf_data: pd.DataFrame,
                           primary_data: pd.DataFrame) -> pd.DataFrame:
        """
        –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –≤—ã—Å—à–µ–≥–æ –¢–§ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π
        
        Args:
            higher_tf_data: –î–∞–Ω–Ω—ã–µ –≤—ã—Å—à–µ–≥–æ –¢–§
            primary_data: –î–∞–Ω–Ω—ã–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¢–§
        
        Returns:
            pd.DataFrame: –í—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        # Forward-fill –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤
        aligned = higher_tf_data.reindex(
            primary_data.index,
            method='ffill'
        )
        
        return aligned


class MultiframeFeatureBuilder:
    """
    –ü–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    
    –°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤:
        - –ü–æ–∑–∏—Ü–∏—è —Ü–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥–Ω–µ–≤–Ω—ã—Ö High/Low
        - –ù–µ–¥–µ–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥
        - –ú–µ—Å—è—á–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        - –ú–µ–∂—Ñ—Ä–µ–π–º–æ–≤–∞—è –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è
    """
    
    def __init__(self,
                 loader: MultiframeLoader,
                 feature_config: Optional[Dict] = None):
        """
        Args:
            loader: –ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
            feature_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        self.loader = loader
        self.config = feature_config or self._default_config()
        self.data: Dict[str, pd.DataFrame] = {}
    
    def _default_config(self) -> Dict:
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            'use_price_position': True,    # –ü–æ–∑–∏—Ü–∏—è –≤ High/Low range
            'use_trend_direction': True,   # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞
            'use_volatility_ratio': True,  # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–µ–π
            'use_divergence': True,        # –ú–µ–∂—Ñ—Ä–µ–π–º–æ–≤–∞—è –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è
            'use_ma_distance': True        # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —Å–∫–æ–ª—å–∑—è—â–∏—Ö —Å—Ä–µ–¥–Ω–∏—Ö
        }
    
    def load_data(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤"""
        self.data = self.loader.load_all()
    
    def build_features(self) -> pd.DataFrame:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Returns:
            pd.DataFrame: –û—Å–Ω–æ–≤–Ω–æ–π –¢–§ —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        if not self.data:
            self.load_data()
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
        primary_data = self.data[self.loader.primary_tf].copy()
        result = primary_data[['close']].copy()
        
        print(f"\nüîß –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—ã—Å—à–µ–≥–æ –¢–§
        for tf in self.loader.context_tfs:
            if tf not in self.data:
                continue
            
            higher_data = self.data[tf]
            
            # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –¢–§
            aligned = self.loader.resample_to_primary(
                higher_data,
                primary_data
            )
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features = self._create_context_features(
                primary_data,
                aligned,
                tf
            )
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
            for col in features.columns:
                result[col] = features[col]
            
            print(f"  ‚úì {tf}: {len(features.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –£–¥–∞–ª–µ–Ω–∏–µ NaN
        initial_len = len(result)
        result = result.dropna()
        dropped = initial_len - len(result)
        
        if dropped > 0:
            print(f"  ‚ÑπÔ∏è –£–¥–∞–ª–µ–Ω–æ {dropped} NaN —Å—Ç—Ä–æ–∫")
        
        print(f"\n  üìä –ò—Ç–æ–≥–æ: {len(result.columns) - 1} –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        return result
    
    def _create_context_features(self,
                                primary: pd.DataFrame,
                                context: pd.DataFrame,
                                tf_name: str) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–¥–Ω–æ–≥–æ –≤—ã—Å—à–µ–≥–æ –¢–§
        
        Args:
            primary: –û—Å–Ω–æ–≤–Ω–æ–π –¢–§
            context: –í—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã–π –≤—ã—Å—à–∏–π –¢–§
            tf_name: –ù–∞–∑–≤–∞–Ω–∏–µ –¢–§ (–¥–ª—è –∏–º–µ–Ω –∫–æ–ª–æ–Ω–æ–∫)
        
        Returns:
            pd.DataFrame: –ü—Ä–∏–∑–Ω–∞–∫–∏
        """
        features = pd.DataFrame(index=primary.index)
        
        # 1. –ü–æ–∑–∏—Ü–∏—è —Ü–µ–Ω—ã –≤ High/Low range
        if self.config['use_price_position'] and 'high' in context.columns:
            high = context['high']
            low = context['low']
            close = primary['close']
            
            range_size = high - low
            price_position = (close - low) / range_size.replace(0, 1)
            
            features[f'price_pos_{tf_name}'] = price_position
        
        # 2. –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞ (—á–µ—Ä–µ–∑ EMA)
        if self.config['use_trend_direction']:
            close = context['close']
            
            # –ë—ã—Å—Ç—Ä–∞—è –∏ –º–µ–¥–ª–µ–Ω–Ω–∞—è EMA
            ema_fast = close.ewm(span=10, adjust=False).mean()
            ema_slow = close.ewm(span=30, adjust=False).mean()
            
            # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –¢–§
            ema_fast_aligned = ema_fast.reindex(primary.index, method='ffill')
            ema_slow_aligned = ema_slow.reindex(primary.index, method='ffill')
            
            trend = (ema_fast_aligned - ema_slow_aligned) / ema_slow_aligned
            features[f'trend_{tf_name}'] = trend
        
        # 3. –û—Ç–Ω–æ—à–µ–Ω–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–µ–π
        if self.config['use_volatility_ratio']:
            # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –≤—ã—Å—à–µ–≥–æ –¢–§
            context_vol = context['close'].pct_change().rolling(14).std()
            context_vol_aligned = context_vol.reindex(
                primary.index,
                method='ffill'
            )
            
            # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¢–§
            primary_vol = primary['close'].pct_change().rolling(14).std()
            
            # –û—Ç–Ω–æ—à–µ–Ω–∏–µ
            vol_ratio = primary_vol / context_vol_aligned.replace(0, 1)
            features[f'vol_ratio_{tf_name}'] = vol_ratio
        
        # 4. –î–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è (—Ä–∞–∑–Ω–∏—Ü–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π)
        if self.config['use_divergence']:
            # ROC (Rate of Change) –Ω–∞ –æ–±–æ–∏—Ö –¢–§
            primary_roc = primary['close'].pct_change(5)
            context_roc = context['close'].pct_change(5)
            context_roc_aligned = context_roc.reindex(
                primary.index,
                method='ffill'
            )
            
            # –î–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è = –∑–Ω–∞–∫(primary_roc) != –∑–Ω–∞–∫(context_roc)
            divergence = np.sign(primary_roc) * np.sign(context_roc_aligned)
            features[f'divergence_{tf_name}'] = divergence
        
        # 5. –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ MA –≤—ã—Å—à–µ–≥–æ –¢–§
        if self.config['use_ma_distance']:
            ma = context['close'].rolling(20).mean()
            ma_aligned = ma.reindex(primary.index, method='ffill')
            
            distance = (primary['close'] - ma_aligned) / ma_aligned
            features[f'ma_dist_{tf_name}'] = distance
        
        return features


# === –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° –û–°–ù–û–í–ù–û–ô –°–ò–°–¢–ï–ú–û–ô ===

def create_multiframe_features(
    data_path: str,
    symbol: str,
    primary_tf: str = 'H1',
    context_tfs: Optional[List[str]] = None,
    config: Optional[Dict] = None
) -> pd.DataFrame:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    
    Args:
        data_path: –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
        symbol: –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
        primary_tf: –û—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º
        context_tfs: –í—ã—Å—à–∏–µ –¢–§
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    
    Returns:
        pd.DataFrame: –î–∞–Ω–Ω—ã–µ —Å –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
    
    Example:
        >>> df = create_multiframe_features(
        >>>     data_path='./data/raw',
        >>>     symbol='XAUUSD',
        >>>     primary_tf='H1',
        >>>     context_tfs=['D1', 'W1']
        >>> )
        >>> # –¢–µ–ø–µ—Ä—å df —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å D1 –∏ W1
    """
    # –ó–∞–≥—Ä—É–∑—á–∏–∫
    loader = MultiframeLoader(
        data_path,
        symbol,
        primary_tf,
        context_tfs
    )
    
    # –ü–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    builder = MultiframeFeatureBuilder(loader, config)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    features = builder.build_features()
    
    return features


def add_multiframe_to_existing(
    primary_data: pd.DataFrame,
    data_path: str,
    symbol: str,
    primary_tf: str,
    context_tfs: List[str]
) -> pd.DataFrame:
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –¥–∞–Ω–Ω—ã–º
    
    Args:
        primary_data: –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        data_path: –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º –≤—ã—Å—à–∏—Ö –¢–§
        symbol: –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
        primary_tf: –û—Å–Ω–æ–≤–Ω–æ–π –¢–§
        context_tfs: –í—ã—Å—à–∏–µ –¢–§
    
    Returns:
        pd.DataFrame: –î–∞–Ω–Ω—ã–µ —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
    """
    # –°–æ–∑–¥–∞–Ω–∏–µ –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    multiframe = create_multiframe_features(
        data_path,
        symbol,
        primary_tf,
        context_tfs
    )
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    result = primary_data.copy()
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    for col in multiframe.columns:
        if col not in result.columns:
            result[col] = multiframe[col]
    
    # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø–æ –∏–Ω–¥–µ–∫—Å—É
    result = result.loc[result.index.isin(multiframe.index)]
    
    return result.dropna()


# === –í–ê–õ–ò–î–ê–¶–ò–Ø ===

def validate_multiframe_data(data: Dict[str, pd.DataFrame]) -> Tuple[bool, List[str]]:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –º—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
    –ü—Ä–æ–≤–µ—Ä–∫–∏:
        - –ù–∞–ª–∏—á–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¢–§
        - –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
    
    Args:
        data: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Ä–∞–∑–Ω—ã—Ö –¢–§
    
    Returns:
        (valid, errors): –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∏ —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫
    """
    errors = []
    
    if not data:
        errors.append("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        return False, errors
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
    for tf, df in data.items():
        if len(df) < 1000:
            errors.append(f"{tf}: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö ({len(df)} < 1000)")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
    date_ranges = {
        tf: (df.index.min(), df.index.max())
        for tf, df in data.items()
    }
    
    # –í—Å–µ –¢–§ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è –¥–∏–∞–ø–∞–∑–æ–Ω—ã
    all_starts = [start for start, _ in date_ranges.values()]
    all_ends = [end for _, end in date_ranges.values()]
    
    latest_start = max(all_starts)
    earliest_end = min(all_ends)
    
    if latest_start >= earliest_end:
        errors.append(
            f"–í—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è: "
            f"{latest_start} >= {earliest_end}"
        )
    
    return len(errors) == 0, errors